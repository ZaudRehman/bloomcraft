//! Tree-structured Bloom filter for hierarchical data organization.
//!
//! A Bloom filter variant that organizes filters in a user-defined tree hierarchy,
//! enabling location-aware membership testing and spatial queries. Optimized for
//! cache efficiency, pruned search, and incremental updates.
//!
//! # Architecture
//!
//! ```text
//! Level 0 (Root): [========= Aggregation Filter =========]
//!                       ↓       ↓       ↓
//! Level 1:        [Filter 0] [Filter 1] [Filter 2]
//!                       ↓        ↓          ↓
//! Level 2:        [F 0.0]     [F 1.0]    [F 2.0]
//!                 [F 0.1]     [F 1.1]    [F 2.1]
//! ```
//!
//! # Tutorial: Building a CDN Cache Tracker
//!
//! ## Step 1: Define Your Hierarchy
//!
//! Our CDN has:
//! - 5 geographic regions (NA, EU, APAC, LATAM, ME)
//! - 20 Points of Presence (POPs) per region
//! - 100 edge servers per POP
//!
//! This gives us a 3-level tree with branching [5, 20, 100] = 10,000 leaf nodes.
//!
//! ## Step 2: Size Your Filters
//!
//! ```rust
//! use bloomcraft::filters::TreeBloomFilter;
//!
//! let mut cache_tracker: TreeBloomFilter<String> =
//!     TreeBloomFilter::new(
//!         vec![5, 20, 100],
//!         50_000,
//!         0.001
//!     ).unwrap();
//! ```

//!
//! ## Step 3: Invalidate Caches
//!
//! ```rust
//! # use bloomcraft::filters::TreeBloomFilter;
//! # let mut cache_tracker: TreeBloomFilter<String> =
//! #     TreeBloomFilter::new(vec![5, 20, 100], 50_000, 0.001).unwrap();
//! # cache_tracker.insert_to_bin(&"/assets/logo.png".to_string(), &[0, 0, 0]).unwrap();
//! let locations = cache_tracker.locate(&"/assets/logo.png".to_string());
//! for loc in locations {
//!     println!("Invalidating cache at path={:?}", loc);
//! }
//! ```
//!
//! # Serialization Security
//!
//! When using the `serde` feature, TreeBloomFilter includes **type-safe serialization**
//! to prevent type confusion attacks:
//!
//! ## Protection Mechanism
//!
//! 1. **TypeId validation**: Serialized filters include `std::any::TypeId` of the hasher type
//! 2. **Deserialization check**: Mismatched TypeIds cause immediate deserialization failure
//! 3. **Backward compatibility**: Older serialized filters (pre-TypeId) fall back to string checks
//!
//! ## Attack Prevention
//!
//! Without TypeId validation, an attacker could:
//! - Deserialize `TreeBloomFilter<T, MaliciousHasher>` as `TreeBloomFilter<T, StdHasher>`
//! - Bypass security checks via type confusion
//! - Inject malicious hash functions
//!
//! TypeId makes this **cryptographically infeasible** because:
//! - `TypeId` is generated by the compiler and cannot be forged
//! - Type aliases don't affect TypeId (unlike `type_name()`)
//! - Mismatched types fail at deserialization, not at runtime
//!
//! ## Example
//!
//! ```ignore
//! use bloomcraft::filters::TreeBloomFilter;
//! use bloomcraft::hash::StdHasher;
//!
//! let filter: TreeBloomFilter<String, StdHasher> = 
//!     TreeBloomFilter::new(vec![2, 3], 1000, 0.01)?;
//!
//! // Serialize with TypeId protection
//! let bytes = bincode::serialize(&filter)?;
//!
//! // Deserialize - TypeId is automatically validated
//! let restored: TreeBloomFilter<String, StdHasher> = bincode::deserialize(&bytes)?;
//!
//! // Attempting wrong hasher type fails immediately:
//! // let wrong: TreeBloomFilter<String, WyHasher> = bincode::deserialize(&bytes)?;
//! // Error: Hasher TypeId mismatch
//! # Ok::<(), Box<dyn std::error::Error>>(())
//! ```


#![allow(clippy::pedantic)]
#![allow(clippy::module_name_repetitions)]
#![allow(dead_code)]
#![allow(private_interfaces)] 

use crate::core::filter::BloomFilter;
use crate::error::{BloomCraftError, Result};
use crate::filters::standard::StandardBloomFilter;
use crate::hash::{BloomHasher, StdHasher};
use std::hash::Hash;
use std::marker::PhantomData;

#[cfg(feature = "metrics")]
use std::sync::atomic::{AtomicUsize, Ordering};

#[cfg(feature = "serde")]
use serde::{Deserialize, Serialize, Deserializer, Serializer};

#[cfg(feature = "metrics")]
use crate::metrics::LatencyHistogram;

#[cfg(feature = "rayon")]
use rayon::prelude::*;

/// Maximum tree depth to prevent exponential memory growth.
///
/// This limit ensures:
/// - Reasonable memory usage (prevents branching factor overflow)
/// - Stack-safe operations (depth 256 = ~2KB stack for iterative traversal)
/// - Coverage of virtually all real-world hierarchies
///
/// Real-world depths:
/// - Filesystems: 10-30 levels
/// - Organizational charts: 5-15 levels
/// - Parse trees: 50-150 levels
/// - Network topologies: 5-10 levels
pub const MAX_TREE_DEPTH: usize = 256;

/// Maximum total nodes across entire tree to prevent memory exhaustion.
///
/// With typical configuration (1K items/bin, 1% FPR):
/// - 10M nodes ≈ 120 GB memory
/// - Calculation includes all internal + leaf nodes
pub const MAX_TOTAL_NODES: usize = 10_000_000;

/// Lemire's fast range reduction for unbiased bin distribution.
///
/// Avoids modulo bias: `hash % n` is biased when n doesn't divide 2^64.
/// This uses multiply-shift reduction for uniform distribution.
///
/// Reference: Daniel Lemire (2019) "Fast Random Integer Generation in an Interval"
#[inline(always)]
fn lemire_reduce(hash: u64, range: usize) -> usize {
    ((hash as u128 * range as u128) >> 64) as usize
}

/// Enhanced hash mixing using SplitMix64 finalizer.
///
/// Provides better avalanche than WyHash for bin distribution.
/// Each bit of input affects all bits of output with ~50% probability.
#[inline(always)]
fn mix_hash_fast(mut h: u64) -> u64 {
    h ^= h >> 30;
    h = h.wrapping_mul(0xbf58476d1ce4e5b9);
    h ^= h >> 27;
    h = h.wrapping_mul(0x94d049bb133111eb);
    h ^= h >> 31;
    h
}

/// Convert a hashable item to bytes using Rust's Hash trait.
#[inline]
fn hash_item_to_bytes<T: Hash>(item: &T) -> [u8; 8] {
    use std::collections::hash_map::DefaultHasher;
    use std::hash::Hasher;
    let mut hasher = DefaultHasher::new();
    item.hash(&mut hasher);
    hasher.finish().to_le_bytes()
}

/// Metadata for TreeNode (cold path - rarely accessed).
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
struct NodeMetadata {
    /// Path to this node (for debugging/statistics)
    path: Vec<usize>,
    /// Level in the tree (0 = root)
    #[allow(dead_code)]
    level: u8,
}

/// Node in the tree-structured Bloom filter with optimized cache layout.
///
/// Hot data (filter, item_count) is separated from cold metadata for better cache utilization.
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
#[repr(C, align(64))]
pub struct TreeNode<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Bloom filter for this node
    filter: StandardBloomFilter<T, H>,
    /// Number of items inserted (for load tracking)
    item_count: usize,
    /// Child nodes (empty for leaf nodes)
    children: Box<[TreeNode<T, H>]>,
    /// Metadata
    metadata: NodeMetadata,
}

impl<T, H> TreeNode<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Create a new leaf node.
    #[inline]
    fn new_leaf(capacity: usize, fpr: f64, hasher: H, path: Vec<usize>, level: u8) -> Result<Self> {
        Ok(Self {
            filter: StandardBloomFilter::with_hasher(capacity, fpr, hasher)?,
            children: Box::new([]),
            item_count: 0,
            metadata: NodeMetadata { path, level },
        })
    }

    /// Create a new internal node with children.
    #[inline]
    fn new_internal(
        capacity: usize,
        fpr: f64,
        hasher: H,
        path: Vec<usize>,
        level: u8,
        children: Box<[TreeNode<T, H>]>,
    ) -> Result<Self> {
        Ok(Self {
            filter: StandardBloomFilter::with_hasher(capacity, fpr, hasher)?,
            children,
            item_count: 0,
            metadata: NodeMetadata { path, level },
        })
    }

    /// Check if this is a leaf node.
    #[inline(always)]
    const fn is_leaf(&self) -> bool {
        self.children.is_empty()
    }

    /// Get total number of nodes in subtree (including self).
    #[inline]
    fn node_count(&self) -> usize {
        1 + self.children.iter().map(|c| c.node_count()).sum::<usize>()
    }

    /// Get memory usage estimate of subtree in bytes.
    #[inline]
    fn memory_usage_estimate(&self) -> usize {
        let filter_bytes = (self.filter.bit_count() + 7) / 8;
        let children_bytes: usize = self.children.iter()
            .map(|c| c.memory_usage_estimate())
            .sum();
        let overhead = std::mem::size_of::<Self>();
        filter_bytes + children_bytes + overhead
    }

    /// Get load factor (items / capacity) for this node.
    #[inline]
    fn load_factor(&self) -> f64 {
        let capacity = self.filter.expected_items();
        if capacity == 0 {
            0.0
        } else {
            self.item_count as f64 / capacity as f64
        }
    }
}

/// Tree-structured Bloom filter for hierarchical data organization.
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct TreeBloomFilter<T, H = StdHasher>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Root node of tree
    root: TreeNode<T, H>,
    /// Branching factors for each level
    branching: Vec<usize>,
    /// Expected items per leaf bin
    capacity_per_bin: usize,
    /// Target false positive rate
    #[allow(dead_code)]
    target_fpr: f64,
    /// Total items inserted across all bins
    total_items: usize,
    /// Hasher for items
    #[cfg_attr(feature = "serde", serde(skip, default = "H::default"))]
    hasher: H,
    /// Phantom data for type parameter T
    #[cfg_attr(feature = "serde", serde(skip))]
    _phantom: PhantomData<T>,
    
    // METRICS (feature-gated)
    #[cfg(feature = "metrics")]
    #[cfg_attr(feature = "serde", serde(skip))]
    metrics: TreeFilterMetrics,
}

// Metrics/Observability (feature-gated)
#[cfg(feature = "metrics")]
#[derive(Debug)]
struct TreeFilterMetrics {
    insert_latency: LatencyHistogram,
    query_latency: LatencyHistogram,
    locate_latency: LatencyHistogram,
    pruned_subtrees: AtomicUsize,
}

#[cfg(feature = "metrics")]
impl Default for TreeFilterMetrics {
    fn default() -> Self {
        Self {
            insert_latency: LatencyHistogram::new(),
            query_latency: LatencyHistogram::new(),
            locate_latency: LatencyHistogram::new(),
            pruned_subtrees: AtomicUsize::new(0),
        }
    }
}

#[cfg(feature = "metrics")]
#[derive(Debug, Clone)]
pub enum HealthStatus {
    Healthy,
    Degraded,
    Critical,
}

#[cfg(feature = "metrics")]
#[derive(Debug, Clone)]
pub struct TreeHealthCheck {
    pub status: HealthStatus,
    pub avg_load_factor: f64,
    pub total_items: usize,
    pub capacity: usize,
    pub saturation: f64,
}

/// Iterator over all bins that might contain an item.
///
/// Created by [`TreeBloomFilter::locate_iter`]. Yields `Vec<usize>` paths
/// lazily without pre-allocating all results.
///
/// # Examples
///
/// ```ignore
/// use bloomcraft::filters::TreeBloomFilter;
/// let mut filter = TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
/// 
/// for path in filter.locate_iter(&"item") {
///     println!("Match at: {:?}", path);
/// }
/// # Ok::<(), Box<dyn std::error::Error>>(())
/// ```
pub struct LocateIter<'a, T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Reference to the tree being queried
    tree: &'a TreeBloomFilter<T, H>,
    /// Item being searched for
    item: &'a T,
    /// DFS stack: (node_ref, current_path)
    stack: Vec<(&'a TreeNode<T, H>, Vec<usize>)>,
    /// Whether iteration has started
    started: bool,
}

impl<'a, T, H> LocateIter<'a, T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    fn new(tree: &'a TreeBloomFilter<T, H>, item: &'a T) -> Self {
        Self {
            tree,
            item,
            stack: Vec::new(),
            started: false,
        }
    }
}

impl<'a, T, H> Iterator for LocateIter<'a, T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    type Item = Vec<usize>;
    
    fn next(&mut self) -> Option<Self::Item> {
        // Initialize on first call
        if !self.started {
            self.started = true;
            
            // Early exit if root doesn't contain item
            if !self.tree.root.filter.contains(self.item) {
                return None;
            }
            
            self.stack.push((&self.tree.root, Vec::new()));
        }
        
        // DFS traversal
        while let Some((node, current_path)) = self.stack.pop() {
            // Found a leaf - return this path
            if node.is_leaf() {
                return Some(current_path);
            }
            
            // Prefetch children (same optimization as locate)
            #[cfg(target_arch = "x86_64")]
            {
                use std::arch::x86_64::{_mm_prefetch, _MM_HINT_T0};
                for child in node.children.iter() {
                    let child_ptr = child as *const _ as *const i8;
                    unsafe {
                        _mm_prefetch(child_ptr, _MM_HINT_T0);
                    }
                }
            }
            
            // Check children (reverse for DFS consistency)
            for (child_idx, child) in node.children.iter().enumerate().rev() {
                if !child.filter.contains(self.item) {
                    continue;
                }
                
                let mut child_path = current_path.clone();
                child_path.push(child_idx);
                self.stack.push((child, child_path));
            }
        }
        
        // No more matches
        None
    }
}

#[cfg(feature = "serde")]
impl<T, H> Serialize for TreeBloomFilter<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default + Serialize,
{
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        use serde::ser::SerializeStruct;
        
        // Serialize TypeId as a debug string (stable within same binary)
        let type_id = std::any::TypeId::of::<H>();
        let type_id_debug = format!("{:?}", type_id);
        
        let mut state = serializer.serialize_struct("TreeBloomFilter", 7)?;
        state.serialize_field("root", &self.root)?;
        state.serialize_field("branching", &self.branching)?;
        state.serialize_field("capacity_per_bin", &self.capacity_per_bin)?;
        state.serialize_field("target_fpr", &self.target_fpr)?;
        state.serialize_field("total_items", &self.total_items)?;
        
        // Human-readable type name (for debugging)
        state.serialize_field("hasher_type", std::any::type_name::<H>())?;
        
        // Cryptographically-secure type identifier
        state.serialize_field("hasher_type_id", &type_id_debug)?;
        
        state.end()
    }
}

#[cfg(feature = "serde")]
impl<'de, T, H> Deserialize<'de> for TreeBloomFilter<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default + Deserialize<'de>,
{
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        use serde::de::{self, Visitor, MapAccess};
        
        struct TreeBloomFilterVisitor<T, H>(PhantomData<(T, H)>);
        
        impl<'de, T, H> Visitor<'de> for TreeBloomFilterVisitor<T, H>
        where
            T: Hash + Send + Sync,
            H: BloomHasher + Clone + Default + Deserialize<'de>,
        {
            type Value = TreeBloomFilter<T, H>;
            
            fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
                formatter.write_str("struct TreeBloomFilter")
            }
            
            fn visit_map<A>(self, mut map: A) -> std::result::Result<Self::Value, A::Error>
            where
                A: MapAccess<'de>,
            {
                let mut root = None;
                let mut branching = None;
                let mut capacity_per_bin = None;
                let mut target_fpr = None;
                let mut total_items = None;
                let mut hasher_type = None;
                let mut hasher_type_id = None;
                
                while let Some(key) = map.next_key::<String>()? {
                    match key.as_str() {
                        "root" => root = Some(map.next_value()?),
                        "branching" => branching = Some(map.next_value()?),
                        "capacity_per_bin" => capacity_per_bin = Some(map.next_value()?),
                        "target_fpr" => target_fpr = Some(map.next_value()?),
                        "total_items" => total_items = Some(map.next_value()?),
                        "hasher_type" => hasher_type = Some(map.next_value::<String>()?),
                        "hasher_type_id" => hasher_type_id = Some(map.next_value::<String>()?),
                        _ => { let _ = map.next_value::<serde::de::IgnoredAny>()?; }
                    }
                }
                
                let root = root.ok_or_else(|| de::Error::missing_field("root"))?;
                let branching = branching.ok_or_else(|| de::Error::missing_field("branching"))?;
                let capacity_per_bin = capacity_per_bin.ok_or_else(|| de::Error::missing_field("capacity_per_bin"))?;
                let target_fpr = target_fpr.ok_or_else(|| de::Error::missing_field("target_fpr"))?;
                let total_items = total_items.ok_or_else(|| de::Error::missing_field("total_items"))?;
                
                // Validate hasher type using TypeId (unforgeable)
                let expected_type_id = std::any::TypeId::of::<H>();
                let expected_type_id_debug = format!("{:?}", expected_type_id);
                
                if let Some(serialized_type_id) = hasher_type_id {
                    if serialized_type_id != expected_type_id_debug {
                        return Err(de::Error::custom(format!(
                            "Hasher TypeId mismatch: expected {:?}, got {}. \
                             This prevents deserialization attacks via type confusion.",
                            expected_type_id,
                            serialized_type_id
                        )));
                    }
                } else {
                    // Backward compatibility: fall back to string check (with warning)
                    if let Some(ht) = hasher_type {
                        let expected = std::any::type_name::<H>();
                        if ht != expected {
                            return Err(de::Error::custom(format!(
                                "Hasher type mismatch (legacy check): expected {}, got {}. \
                                 NOTE: This filter was serialized with an older version. \
                                 Re-serialize with current version for TypeId protection.",
                                expected, ht
                            )));
                        }
                    } else {
                        // Missing both fields - reject
                        return Err(de::Error::custom(
                            "Missing hasher type validation fields (hasher_type_id and hasher_type)"
                        ));
                    }
                }
                
                Ok(TreeBloomFilter {
                    root,
                    branching,
                    capacity_per_bin,
                    target_fpr,
                    total_items,
                    hasher: H::default(),  
                    _phantom: PhantomData,
                    #[cfg(feature = "metrics")]
                    metrics: TreeFilterMetrics::default(),
                })
            }
        }
        
        deserializer.deserialize_struct(
            "TreeBloomFilter",
            &["root", "branching", "capacity_per_bin", "target_fpr", "total_items", "hasher_type", "hasher_type_id"],
            TreeBloomFilterVisitor(PhantomData)
        )
    }
}

impl<T> TreeBloomFilter<T, StdHasher>
where
    T: Hash + Send + Sync,
{
    /// Create a new tree-structured Bloom filter with default hasher.
    ///
    /// # Errors
    /// Returns `Err` if parameters are invalid (see [`with_hasher`](Self::with_hasher) for details).
    #[must_use]
    pub fn new(branching: Vec<usize>, capacity_per_bin: usize, fpr: f64) -> Result<Self> {
        Self::with_hasher(branching, capacity_per_bin, fpr, StdHasher::new())
    }
}

impl<T, H> TreeBloomFilter<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Create a new tree-structured Bloom filter with custom hasher.
    ///
    /// # Errors
    /// - `InvalidParameters` if branching is empty or contains zeros
    /// - `InvalidParameters` if depth exceeds MAX_TREE_DEPTH (256)
    /// - `InvalidParameters` if total nodes would overflow or exceed MAX_TOTAL_NODES
    /// - `FalsePositiveRateOutOfBounds` if fpr not in (0, 1)
    /// - `InvalidItemCount` if capacity_per_bin is 0
    ///
    /// # Examples
    /// ```ignore
    /// let filter = TreeBloomFilter::with_hasher(
    ///     vec![2, 3],
    ///     1000,
    ///     0.01,
    ///     StdHasher::new(),
    /// )?;
    /// # Ok::<(), Box<dyn std::error::Error>>(());
    /// ```
    #[must_use]
    pub fn with_hasher(
        branching: Vec<usize>,
        capacity_per_bin: usize,
        fpr: f64,
        hasher: H,
    ) -> Result<Self> {
        // Validate basic parameters
        if branching.is_empty() {
            return Err(BloomCraftError::invalid_parameters("branching cannot be empty"));
        }
        
        if !branching.iter().all(|&b| b > 0) {
            return Err(BloomCraftError::invalid_parameters("all branching factors must be > 0"));
        }
        
        if capacity_per_bin == 0 {
            return Err(BloomCraftError::invalid_item_count(capacity_per_bin));
        }
        
        if !(fpr > 0.0 && fpr < 1.0) {
            return Err(BloomCraftError::fp_rate_out_of_bounds(fpr));
        }
        
        // Validate depth
        if branching.len() > MAX_TREE_DEPTH {
            return Err(BloomCraftError::invalid_parameters(format!(
                "tree depth {} exceeds maximum {}",
                branching.len(),
                MAX_TREE_DEPTH
            )));
        }
        
        // Calculate total nodes with overflow protection
        let leaf_count: usize = branching.iter()
            .try_fold(1usize, |acc, &b| acc.checked_mul(b))
            .ok_or_else(|| BloomCraftError::invalid_parameters(
                format!("Branching factors {:?} would overflow leaf count", branching)
            ))?;
        
        let mut total_nodes = leaf_count;
        let mut partial_product: usize = 1;
        for i in 0..branching.len() - 1 {
            partial_product = partial_product.checked_mul(branching[i])
                .ok_or_else(|| BloomCraftError::invalid_parameters(
                    format!("Branching factor at level {} causes overflow", i)
                ))?;
            total_nodes = total_nodes.checked_add(partial_product)
                .ok_or_else(|| BloomCraftError::invalid_parameters(
                    "Total node count would overflow"
                ))?;
        }
        
        // Enforce hard limit on total nodes
        if total_nodes > MAX_TOTAL_NODES {
            let estimated_memory = total_nodes * std::mem::size_of::<TreeNode<T, H>>();
            return Err(BloomCraftError::invalid_parameters(format!(
                "Tree would allocate {} nodes (max: {}). Estimated memory: {} MB. \
                Consider reducing branching factors or depth.",
                total_nodes,
                MAX_TOTAL_NODES,
                estimated_memory / (1024 * 1024)
            )));
        }
        
        // Warning for large trees (not an error)
        if total_nodes > 100_000 {
            eprintln!(
                "WARNING: TreeBloomFilter will allocate {} nodes (~{} MB). \
                This is within limits but may impact performance.",
                total_nodes,
                (total_nodes * std::mem::size_of::<TreeNode<T, H>>()) / (1024 * 1024)
            );
        }
        
        let root = Self::build_tree(&branching, 0, capacity_per_bin, fpr, hasher.clone(), vec![]);
        
        Ok(Self {
            root: root?,
            branching,
            capacity_per_bin,
            target_fpr: fpr,
            total_items: 0,
            hasher,
            _phantom: PhantomData,
            #[cfg(feature = "metrics")]
            metrics: TreeFilterMetrics::default(),
        })
    }

    /// Recursively build the tree with breadth-first layout.
    fn build_tree(
        branching: &[usize],
        level: usize,
        capacity: usize,
        fpr: f64,
        hasher: H,
        path: Vec<usize>,
    ) -> Result<TreeNode<T, H>> {
        if level >= branching.len() {
            return TreeNode::new_leaf(capacity, fpr, hasher, path, level as u8);
        }

        let num_children = branching[level];
        let mut children = Vec::with_capacity(num_children);
        for i in 0..num_children {
            let mut child_path = path.clone();
            child_path.push(i);
            let child = Self::build_tree(
                branching,
                level + 1,
                capacity,
                fpr,
                hasher.clone(),
                child_path,
            )?;
            children.push(child);
        }

        let internal_capacity = capacity * num_children;
        TreeNode::new_internal(
            internal_capacity,
            fpr,
            hasher,
            path,
            level as u8,
            children.into_boxed_slice(),
        )
    }

    /// Validate a bin path against tree structure.
    #[inline]
    fn validate_path(&self, path: &[usize]) -> Result<()> {
        if path.len() != self.depth() {
            return Err(BloomCraftError::invalid_parameters(format!(
                "Path length {} does not match tree depth {}",
                path.len(),
                self.depth()
            )));
        }

        for (level, &idx) in path.iter().enumerate() {
            if idx >= self.branching[level] {
                return Err(BloomCraftError::invalid_parameters(format!(
                    "Path index {} at level {} exceeds branching factor {}",
                    idx, level, self.branching[level]
                )));
            }
        }
        Ok(())
    }

    /// Get the depth (number of levels) in the tree.
    ///
    /// # Examples
    /// ```
    /// use bloomcraft::filters::TreeBloomFilter;
    /// let filter = TreeBloomFilter::<String>::new(vec![3, 4], 1000, 0.01).unwrap();
    /// assert_eq!(filter.depth(), 2);
    /// ```
    #[must_use]
    #[inline(always)]
    pub const fn depth(&self) -> usize {
        self.branching.len()
    }

    /// Get the total number of leaf bins.
    ///
    /// This is the product of all branching factors.
    #[must_use]
    #[inline]
    pub fn leaf_count(&self) -> usize {
        self.branching.iter().product()
    }

    /// Get the total number of nodes (internal + leaf) in the tree.
    #[must_use]
    #[inline]
    pub fn node_count(&self) -> usize {
        self.root.node_count()
    }

    /// Get estimated memory usage in bytes.
    ///
    /// Includes all filters, metadata, and tree structure overhead.
    #[must_use]
    #[inline]
    pub fn memory_usage(&self) -> usize {
        self.root.memory_usage_estimate() + std::mem::size_of::<Self>()
    }

    /// Insert an item using automatic hash-based routing.
    #[inline]
    pub fn insert(&mut self, item: &T) -> Result<()> {
        self.insert_auto(item)
    }

    /// Insert an item into a specific bin.
    ///
    /// The item is inserted at all levels along the path from root to leaf.
    ///
    /// # Errors
    /// Returns error if `bin_path` is invalid (wrong length or out-of-bounds).
    #[inline]
    pub fn insert_to_bin(&mut self, item: &T, bin_path: &[usize]) -> Result<()> {
        #[cfg(feature = "metrics")]
        let start = std::time::Instant::now();
        
        self.validate_path(bin_path)?;
        let mut current = &mut self.root;
        current.filter.insert(item);
        current.item_count += 1;

        for &child_idx in bin_path {
            current = &mut current.children[child_idx];
            current.filter.insert(item);
            current.item_count += 1;
        }

        self.total_items += 1;
        
        #[cfg(feature = "metrics")]
        {
            let elapsed = start.elapsed().as_nanos() as u64;
            self.metrics.insert_latency.record(elapsed);
        }
        
        Ok(())
    }

    /// Insert multiple items into the same bin with atomicity guarantees.
    ///
    /// This operation is all-or-nothing: if any overflow check fails, no state is modified.
    /// Either all items are inserted successfully, or an error is returned.
    ///
    /// # Safety Guarantees
    /// - Pre-validates all capacity constraints before any mutation
    /// - Uses checked arithmetic to prevent silent integer overflow
    /// - Pre-computes all new counts, then applies atomically
    ///
    /// # Errors
    /// - `InvalidParameters` if `bin_path` is invalid
    /// - `CapacityExceeded` if insertion would overflow any counter
    #[inline]
    pub fn insert_batch_to_bin(&mut self, items: &[&T], bin_path: &[usize]) -> Result<()> {
        if items.is_empty() {
            return Ok(());
        }
        
        self.validate_path(bin_path)?;

        // Check global overflow
        let new_total = self.total_items.checked_add(items.len())
            .ok_or_else(|| BloomCraftError::capacity_exceeded(
                usize::MAX,
                items.len()
            ))?;

        // Pre-compute all new counts (root + all nodes in path)
        let mut new_counts = Vec::with_capacity(bin_path.len() + 1);
        
        // Check root node
        let new_root_count = self.root.item_count.checked_add(items.len())
            .ok_or_else(|| BloomCraftError::capacity_exceeded(
                usize::MAX,
                items.len()
            ))?;
        new_counts.push(new_root_count);

        // Check all nodes along path
        let mut current = &self.root;
        for &child_idx in bin_path {
            current = &current.children[child_idx];
            let new_count = current.item_count.checked_add(items.len())
                .ok_or_else(|| BloomCraftError::capacity_exceeded(
                    usize::MAX,
                    items.len()
                ))?;
            new_counts.push(new_count);
        }

        // Insert into root
        let mut current = &mut self.root;
        for item in items {
            current.filter.insert(item);
        }
        current.item_count = new_counts[0];

        // Insert into all nodes along path
        for (depth, &child_idx) in bin_path.iter().enumerate() {
            current = &mut current.children[child_idx];
            for item in items {
                current.filter.insert(item);
            }
            current.item_count = new_counts[depth + 1];
        }

        self.total_items = new_total;

        Ok(())
    }

    /// Find all bins that might contain an item.
    ///
    /// Returns all leaf bin paths where the item might exist. Uses depth-first
    /// traversal with early pruning when intermediate filters don't contain the item.
    ///
    /// # Thread Safety
    ///
    /// This method is safe to call concurrently from multiple threads because:
    /// 1. `StandardBloomFilter` uses atomic operations for all reads (`contains`)
    /// 2. Prefetching is advisory-only - `_mm_prefetch` does not mutate memory
    /// 3. Tree structure is immutable after construction
    ///
    /// However, `TreeBloomFilter` itself is not `Sync` due to mutation methods.
    /// For concurrent read-only access, wrap in `Arc<TreeBloomFilter>`.
    /// For read-write access, use `Arc<RwLock<TreeBloomFilter>>`.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// use bloomcraft::filters::TreeBloomFilter;
    /// let mut filter = TreeBloomFilter::<String>::new(vec![2, 3], 1000, 0.01)?;
    /// filter.insert_to_bin(&"item".to_string(), &[0, 1])?;
    ///
    /// let locations = filter.locate(&"item".to_string());
    /// // locations = vec![vec![0, 1]]
    /// # Ok::<(), Box<dyn std::error::Error>>(())
    /// ```
    #[must_use]
    pub fn locate(&self, item: &T) -> Vec<Vec<usize>> {
        #[cfg(feature = "metrics")]
        let start = std::time::Instant::now();
        
        if !self.root.filter.contains(item) {
            #[cfg(feature = "metrics")]
            {
                let elapsed = start.elapsed().as_nanos() as u64;
                self.metrics.locate_latency.record(elapsed);
            }
            return Vec::new();
        }

        let mut result = Vec::new();
        let mut stack = vec![(&self.root, Vec::new())];
        
        while let Some((node, current_path)) = stack.pop() {
            if node.is_leaf() {
                result.push(current_path);
                continue;
            }

            // Prefetch children for cache optimization
            #[cfg(target_arch = "x86_64")]
            {
                use std::arch::x86_64::{_mm_prefetch, _MM_HINT_T0};
                for child in node.children.iter() {
                    let child_ptr = child as *const _ as *const i8;
                    unsafe {
                        _mm_prefetch(child_ptr, _MM_HINT_T0);
                    }
                }
            }

            // Now check filters (data likely in cache)
            for (child_idx, child) in node.children.iter().enumerate().rev() {
                if !child.filter.contains(item) {
                    #[cfg(feature = "metrics")]
                    self.metrics.pruned_subtrees.fetch_add(1, Ordering::Relaxed);
                    continue;
                }
                
                let mut child_path = current_path.clone();
                child_path.push(child_idx);
                stack.push((child, child_path));
            }
        }
        
        #[cfg(feature = "metrics")]
        {
            let elapsed = start.elapsed().as_nanos() as u64;
            self.metrics.locate_latency.record(elapsed);
        }
        
        result
    }

    /// Find all bins containing an item using a callback.
    ///
    /// Instead of allocating a `Vec` for each matching path, this method reuses
    /// a single path buffer and calls the provided closure for each match.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use bloomcraft::filters::TreeBloomFilter;
    /// let filter = TreeBloomFilter::<String>::new(vec![2, 3], 1000, 0.01)?;
    ///
    /// // Process immediately without allocating
    /// filter.locate_with(&"item".to_string(), |path| {
    ///     println!("Found at: {:?}", path);
    ///     invalidate_cache(path);
    /// });
    /// # fn invalidate_cache(_: &[usize]) {}
    /// # Ok::<(), Box<dyn std::error::Error>>(())
    /// ```
    #[inline]
    pub fn locate_with<F>(&self, item: &T, mut callback: F)
    where
        F: FnMut(&[usize]),
    {
        #[cfg(feature = "metrics")]
        let start = std::time::Instant::now();
        
        // Early exit if root doesn't contain item
        if !self.root.filter.contains(item) {
            #[cfg(feature = "metrics")]
            {
                let elapsed = start.elapsed().as_nanos() as u64;
                self.metrics.locate_latency.record(elapsed);
            }
            return;
        }
        
        // Stack: (node, path_to_this_node)
        let mut stack: Vec<(&TreeNode<T, H>, Vec<usize>)> = vec![(&self.root, Vec::new())];
        
        while let Some((node, current_path)) = stack.pop() {
            // Leaf node: invoke callback with current path
            if node.is_leaf() {
                callback(&current_path);
                continue;
            }
            
            // Prefetch children for cache optimization
            #[cfg(target_arch = "x86_64")]
            {
                use std::arch::x86_64::{_mm_prefetch, _MM_HINT_T0};
                for child in node.children.iter() {
                    let child_ptr = child as *const _ as *const i8;
                    unsafe {
                        _mm_prefetch(child_ptr, _MM_HINT_T0);
                    }
                }
            }
            
            // Check each child (reverse order for DFS consistency with locate)
            for (child_idx, child) in node.children.iter().enumerate().rev() {
                if !child.filter.contains(item) {
                    #[cfg(feature = "metrics")]
                    self.metrics.pruned_subtrees.fetch_add(1, Ordering::Relaxed);
                    continue;
                }
                
                // Clone path and extend it
                let mut child_path = current_path.clone();
                child_path.push(child_idx);
                
                stack.push((child, child_path));
            }
        }
        
        #[cfg(feature = "metrics")]
        {
            let elapsed = start.elapsed().as_nanos() as u64;
            self.metrics.locate_latency.record(elapsed);
        }
    }

    /// Create an iterator over all bins that might contain an item.
    ///
    /// Lazily evaluates matches instead of pre-allocating all results.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use bloomcraft::filters::TreeBloomFilter;
    /// # let filter = TreeBloomFilter::<String>::new(vec![2, 3], 1000, 0.01)?;
    /// // Find first match only
    /// if let Some(path) = filter.locate_iter(&"item".to_string()).next() {
    ///     println!("First match: {:?}", path);
    /// }
    ///
    /// // Count matches without allocating paths
    /// let count = filter.locate_iter(&"item".to_string()).count();
    /// # Ok::<(), Box<dyn std::error::Error>>(())
    /// ```
    #[must_use]
    pub fn locate_iter<'a>(&'a self, item: &'a T) -> LocateIter<'a, T, H> {
        LocateIter::new(self, item)
    }

    /// Compute the union of two tree filters (merge).
    pub fn union(&mut self, other: &Self) -> Result<()> {
        if self.branching != other.branching {
            return Err(BloomCraftError::incompatible_filters(
                "Different branching factors".to_string()
            ));
        }
        
        Self::union_nodes(&mut self.root, &other.root)?;
        self.total_items += other.total_items;
        Ok(())
    }

    fn union_nodes(a: &mut TreeNode<T, H>, b: &TreeNode<T, H>) -> Result<()> {
        // Union filters at this level
        a.filter = a.filter.union(&b.filter)?;
        a.item_count += b.item_count;
        
        // Recursively union children
        for (a_child, b_child) in a.children.iter_mut().zip(b.children.iter()) {
            Self::union_nodes(a_child, b_child)?;
        }
        
        Ok(())
    }

    /// Compute the intersection of two tree filters.
    pub fn intersect(&mut self, other: &Self) -> Result<()> {
        if self.branching != other.branching {
            return Err(BloomCraftError::incompatible_filters(
                "Different branching factors".to_string()
            ));
        }
        
        Self::intersect_nodes(&mut self.root, &other.root)?;
        self.total_items = 0;  // Unknown after intersect
        Ok(())
    }

    fn intersect_nodes(a: &mut TreeNode<T, H>, b: &TreeNode<T, H>) -> Result<()> {
        // Intersect filters at this level
        a.filter = a.filter.intersect(&b.filter)?;
        a.item_count = 0;  // Unknown
        
        // Recursively intersect children
        for (a_child, b_child) in a.children.iter_mut().zip(b.children.iter()) {
            Self::intersect_nodes(a_child, b_child)?;
        }
        
        Ok(())
    }

    /// Get reference to subtree at path.
    ///
    /// Navigates to a specific node in the tree following the provided path indices.
    /// Returns a reference to the node at that location, or an error if the path is invalid.
    ///
    /// # Path Validation
    ///
    /// The method validates:
    /// 1. **Path length**: Must not exceed tree depth
    /// 2. **Index bounds**: Each index must be within the branching factor at that level
    ///
    /// # Errors
    ///
    /// - `InvalidParameters` if path length exceeds tree depth
    /// - `InvalidParameters` if any index is out of bounds for its level
    pub fn subtree_at(&self, path: &[usize]) -> Result<&TreeNode<T, H>> {
        // Empty path = root node
        if path.is_empty() {
            return Ok(&self.root);
        }
        
        // Validate path length doesn't exceed tree depth
        if path.len() > self.depth() {
            return Err(BloomCraftError::invalid_parameters(format!(
                "Path length {} exceeds tree depth {}",
                path.len(),
                self.depth()
            )));
        }
        
        // Traverse tree, validating each index
        let mut current = &self.root;
        for (level, &idx) in path.iter().enumerate() {
            if idx >= current.children.len() {
                return Err(BloomCraftError::invalid_parameters(format!(
                    "Invalid index {} at level {} (branching factor is {}, valid range: 0..{})",
                    idx,
                    level,
                    current.children.len(),
                    current.children.len()
                )));
            }
            current = &current.children[idx];
        }
        
        Ok(current)
    }

    /// Clear specific subtree.
    ///
    /// Clears all filters and resets item counts in the subtree rooted at the given path.
    /// Uses the same validation logic as [`subtree_at`](Self::subtree_at) for consistency.
    ///
    /// # Validation
    ///
    /// - Path length must not exceed tree depth
    /// - Each index must be within the branching factor at that level
    ///
    /// # Errors
    ///
    /// - `InvalidParameters` if path is invalid (see [`subtree_at`](Self::subtree_at))
    pub fn clear_subtree(&mut self, path: &[usize]) -> Result<()> {
        // Validate path using same logic as subtree_at
        if path.is_empty() {
            Self::clear_node_iterative(&mut self.root);
            return Ok(());
        }
        
        // Validate path length
        if path.len() > self.depth() {
            return Err(BloomCraftError::invalid_parameters(format!(
                "Path length {} exceeds tree depth {}",
                path.len(),
                self.depth()
            )));
        }
        
        // Navigate to target node with validation
        let mut current = &mut self.root;
        for (level, &idx) in path.iter().enumerate() {
            if idx >= current.children.len() {
                return Err(BloomCraftError::invalid_parameters(format!(
                    "Invalid index {} at level {} (branching factor is {}, valid range: 0..{})",
                    idx,
                    level,
                    current.children.len(),
                    current.children.len()
                )));
            }
            current = &mut current.children[idx];
        }
        
        Self::clear_node_iterative(current);
        Ok(())
    }

    /// Locate items within path prefix (range query).
    pub fn locate_in_range(&self, item: &T, path_prefix: &[usize]) -> Vec<Vec<usize>> {
        if path_prefix.is_empty() {
            return self.locate(item);
        }
        
        // Navigate to subtree
        let subtree = match self.subtree_at(path_prefix) {
            Ok(node) => node,
            Err(_) => return Vec::new(),
        };
        
        if !subtree.filter.contains(item) {
            return Vec::new();
        }
        
        // DFS within subtree
        let mut result = Vec::new();
        self.locate_in_subtree(subtree, item, path_prefix.to_vec(), &mut result);
        result
    }

    fn locate_in_subtree(
        &self,
        node: &TreeNode<T, H>,
        item: &T,
        current_path: Vec<usize>,
        result: &mut Vec<Vec<usize>>,
    ) {
        if node.is_leaf() {
            result.push(current_path);
            return;
        }
        
        for (child_idx, child) in node.children.iter().enumerate() {
            if !child.filter.contains(item) {
                continue;
            }
            
            let mut child_path = current_path.clone();
            child_path.push(child_idx);
            self.locate_in_subtree(child, item, child_path, result);
        }
    }

    /// Locate multiple items efficiently.
    #[must_use]
    pub fn locate_batch(&self, items: &[&T]) -> Vec<Vec<Vec<usize>>> {
        items.iter()
            .map(|item| self.locate(item))
            .collect()
    }

    /// Parallel batch locate (requires `rayon` feature).
    #[cfg(feature = "rayon")]
    #[must_use]
    pub fn locate_batch_parallel(&self, items: &[&T]) -> Vec<Vec<Vec<usize>>> {
        items.par_iter()
            .map(|item| self.locate(item))
            .collect()
    }

    /// Check if any leaf needs resizing.
    #[must_use]
    pub fn needs_resize(&self) -> bool {
        self.stats().avg_load_factor > 0.7
    }

    /// Create resized filter with more capacity.
    pub fn resize(&self, new_capacity_per_bin: usize, new_fpr: f64) -> Result<Self> {
        let new_filter = Self::with_hasher(
            self.branching.clone(),
            new_capacity_per_bin,
            new_fpr,
            H::default(),
        )?;
        
        // This returns an empty filter with new capacity
        Ok(new_filter)
    }

    /// Insert item with hash-based bin assignment using unbiased distribution.
    ///
    /// Uses Lemire's fast range reduction to avoid modulo bias.
    ///
    /// # Determinism
    /// Same item always maps to same bin path (deterministic routing).
    pub fn insert_auto(&mut self, item: &T) -> Result<()> {
        let bytes = hash_item_to_bytes(item);
        let (h1, h2) = self.hasher.hash_bytes_pair(&bytes);
        
        let mut bin_path = Vec::with_capacity(self.depth());
        let mut hash = h1;
        
        for (level, &branching_factor) in self.branching.iter().enumerate() {
            // Lemire's fast range reduction (unbiased)
            let index = lemire_reduce(hash, branching_factor);
            bin_path.push(index);
            
            // Stronger mixing: combine h1, h2, and level
            hash = mix_hash_fast(hash ^ h2.wrapping_mul(level as u64 + 1));
        }
        
        self.insert_to_bin(item, &bin_path)
    }

    /// Clear a node and all its descendants with automatic stack overflow protection.
    ///
    /// # Implementation Strategy
    /// - For shallow trees (depth ≤ 64): Simple DFS with stack vector
    /// - For deep trees (depth > 64): Hybrid approach with heap queue
    ///
    /// # Safety
    /// - 100% safe Rust, no unsafe blocks
    /// - No recursion (eliminates stack overflow risk entirely)
    /// - Automatic transition to heap-based clearing for deep trees
    fn clear_node_iterative(node: &mut TreeNode<T, H>) {
        /// Threshold for switching to heap-based clearing
        const STACK_DEPTH_THRESHOLD: usize = 64;
        
        let mut stack: Vec<&mut TreeNode<T, H>> = vec![node];
        
        while let Some(current) = stack.pop() {
            current.filter.clear();
            current.item_count = 0;
            
            // Check if we're approaching risky stack depth
            if stack.len() > STACK_DEPTH_THRESHOLD {
                // Switch to heap-based BFS to avoid stack growth
                Self::clear_remaining_with_queue(&mut stack);
                return;
            }
            
            // Normal DFS path
            for child in current.children.iter_mut() {
                stack.push(child);
            }
        }
    }

    /// Fallback for deep trees: use heap-allocated queue instead of stack.
    fn clear_remaining_with_queue(remaining: &mut Vec<&mut TreeNode<T, H>>) {
        use std::collections::VecDeque;
        
        // Move remaining nodes to a heap-allocated queue
        let mut queue: VecDeque<&mut TreeNode<T, H>> = remaining.drain(..).collect();
        
        // BFS traversal (bounded by tree width, not depth)
        while let Some(current) = queue.pop_front() {
            current.filter.clear();
            current.item_count = 0;
            
            for child in current.children.iter_mut() {
                queue.push_back(child);
            }
        }
    }

    /// Check if item might exist anywhere in the tree.
    #[must_use]
    #[inline(always)]
    pub fn contains(&self, item: &T) -> bool {
        #[cfg(feature = "metrics")]
        let start = std::time::Instant::now();
        
        let result = self.root.filter.contains(item);
        
        #[cfg(feature = "metrics")]
        {
            let elapsed = start.elapsed().as_nanos() as u64;
            self.metrics.query_latency.record(elapsed);
        }
        
        result
    }

    /// Check if item might exist in a specific bin.
    ///
    /// # Errors
    /// Returns error if `bin_path` is invalid.
    #[must_use]
    #[inline]
    pub fn contains_in_bin(&self, item: &T, bin_path: &[usize]) -> Result<bool> {
        self.validate_path(bin_path)?;
        
        if !self.root.filter.contains(item) {
            return Ok(false);
        }

        let mut current = &self.root;
        for &child_idx in bin_path {
            current = &current.children[child_idx];
            if !current.filter.contains(item) {
                return Ok(false);
            }
        }
        Ok(true)
    }

    /// Batch check if items might exist (checks root only).
    #[must_use]
    #[inline]
    pub fn contains_batch(&self, items: &[&T]) -> Vec<bool> {
        items.iter().map(|item| self.contains(item)).collect()
    }

    /// Check if item exists in ALL levels of the tree (expensive).
    ///
    /// Unlike `contains()`, this verifies the item at every level.
    #[must_use]
    pub fn query_all(&self, item: &T) -> bool {
        if !self.root.filter.contains(item) {
            return false;
        }
        self.query_all_recursive(&self.root, item)
    }

    fn query_all_recursive(&self, node: &TreeNode<T, H>, item: &T) -> bool {
        if node.is_leaf() {
            return node.filter.contains(item);
        }
        node.children.iter().any(|child| self.query_all_recursive(child, item))
    }

    /// Get tree statistics (memory, load factor, etc.).
    #[must_use]
    pub fn stats(&self) -> TreeStats {
        let total_nodes = self.node_count();
        let memory_usage = self.memory_usage();
        let leaf_bins = self.leaf_count();
        
        let memory_per_node = if total_nodes > 0 {
            memory_usage / total_nodes
        } else {
            0
        };
        
        let overhead_factor = if leaf_bins > 0 {
            total_nodes as f64 / leaf_bins as f64
        } else {
            0.0
        };
        
        TreeStats {
            total_nodes,
            memory_usage,
            total_items: self.total_items,
            depth: self.depth(),
            leaf_bins,
            avg_load_factor: self.compute_avg_load_factor(),
            memory_per_node,
            overhead_factor,
        }
    }

    fn compute_avg_load_factor(&self) -> f64 {
        let (sum, count) = self.compute_load_factor_recursive(&self.root);
        if count == 0 {
            0.0
        } else {
            sum / count as f64
        }
    }

    fn compute_load_factor_recursive(&self, node: &TreeNode<T, H>) -> (f64, usize) {
        if node.is_leaf() {
            return (node.load_factor(), 1);
        }

        let mut sum = 0.0;
        let mut count = 0;
        for child in &*node.children {
            let (child_sum, child_count) = self.compute_load_factor_recursive(child);
            sum += child_sum;
            count += child_count;
        }
        (sum, count)
    }

    #[cfg(feature = "metrics")]
    pub fn health_check(&self) -> TreeHealthCheck {
        let stats = self.stats();
        let status = if stats.avg_load_factor > 0.9 {
            HealthStatus::Critical
        } else if stats.avg_load_factor > 0.7 {
            HealthStatus::Degraded
        } else {
            HealthStatus::Healthy
        };
        
        TreeHealthCheck {
            status,
            avg_load_factor: stats.avg_load_factor,
            total_items: stats.total_items,
            capacity: self.capacity_per_bin * stats.leaf_bins,
            saturation: stats.avg_load_factor,
        }
    }
    
    #[cfg(feature = "metrics")]
    pub fn export_prometheus(&self) -> String {
        let stats = self.stats();
        format!(
            "# HELP tree_bloom_filter_items Total items inserted\n\
             # TYPE tree_bloom_filter_items gauge\n\
             tree_bloom_filter_items{{depth=\"{}\"}} {}\n\
             # HELP tree_bloom_filter_load_factor Average load factor\n\
             # TYPE tree_bloom_filter_load_factor gauge\n\
             tree_bloom_filter_load_factor{{depth=\"{}\"}} {:.4}\n\
             # HELP tree_bloom_filter_pruned_subtrees Total pruned subtrees\n\
             # TYPE tree_bloom_filter_pruned_subtrees counter\n\
             tree_bloom_filter_pruned_subtrees{{depth=\"{}\"}} {}\n",
            stats.depth, stats.total_items,
            stats.depth, stats.avg_load_factor,
            stats.depth, self.metrics.pruned_subtrees.load(Ordering::Relaxed)
        )
    }

    /// Validate tree structure integrity.
    ///
    /// Checks branching factors and path consistency.
    ///
    /// # Errors
    /// Returns error if structure is invalid.
    #[cfg(debug_assertions)]
    pub fn validate_structure(&self) -> Result<()> {
        self.validate_node(&self.root, &[])?;
        Ok(())
    }

    #[cfg(debug_assertions)]
    fn validate_node(&self, node: &TreeNode<T, H>, current_path: &[usize]) -> Result<()> {
        // Check path matches stored path
        if node.metadata.path != current_path {
            return Err(BloomCraftError::internal_error(format!(
                "Path mismatch: stored {:?}, actual {:?}",
                node.metadata.path, current_path
            )));
        }
        
        // Check children count matches branching factor
        if current_path.len() < self.branching.len() {
            let expected_children = self.branching[current_path.len()];
            if node.children.len() != expected_children {
                return Err(BloomCraftError::internal_error(format!(
                    "Child count mismatch at {:?}: expected {}, got {}",
                    current_path, expected_children, node.children.len()
                )));
            }
        }
        
        // Recursively validate children
        for (idx, child) in node.children.iter().enumerate() {
            let mut child_path = current_path.to_vec();
            child_path.push(idx);
            self.validate_node(child, &child_path)?;
        }
        
        Ok(())
    }
}

/// Statistics about the tree structure and usage.
#[derive(Debug, Clone, Default, Copy)]
pub struct TreeStats {
    /// Total number of nodes (internal + leaf).
    pub total_nodes: usize,
    /// Estimated memory usage in bytes.
    pub memory_usage: usize,
    /// Total items inserted across all bins.
    pub total_items: usize,
    /// Tree depth (number of levels).
    pub depth: usize,
    /// Number of leaf bins.
    pub leaf_bins: usize,
    /// Average load factor (items / capacity) across all nodes.
    pub avg_load_factor: f64,
    /// Memory usage per node (average).
    pub memory_per_node: usize,
    /// Overhead factor (total_nodes / leaf_bins).
    pub overhead_factor: f64,
}

impl<T, H> BloomFilter<T> for TreeBloomFilter<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    fn insert(&mut self, item: &T) {
        let _ = TreeBloomFilter::insert(self, item);
    }

    fn contains(&self, item: &T) -> bool {
        TreeBloomFilter::contains(self, item)
    }

    fn clear(&mut self) {
        Self::clear_node_iterative(&mut self.root);
        self.total_items = 0;
    }

    fn len(&self) -> usize {
        self.total_items
    }

    fn is_empty(&self) -> bool {
        self.total_items == 0
    }

    fn false_positive_rate(&self) -> f64 {
        self.root.filter.false_positive_rate()
    }

    fn expected_items(&self) -> usize {
        self.capacity_per_bin
    }

    fn bit_count(&self) -> usize {
        self.root.filter.bit_count()
    }

    fn hash_count(&self) -> usize {
        self.root.filter.hash_count()
    }
}

/// Builder for constructing TreeBloomFilter with custom parameters.
///
/// # Examples
///
/// ```ignore
/// # use bloomcraft::filters::tree::TreeBloomFilterBuilder;
/// let filter = TreeBloomFilterBuilder::<String>::new()
///     .branching(vec![5, 10])
///     .capacity_per_bin(1000)
///     .false_positive_rate(0.01)
///     .build()?;
/// # Ok::<(), Box<dyn std::error::Error>>(())
/// ```
pub struct TreeBloomFilterBuilder<T, H = StdHasher>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    branching: Option<Vec<usize>>,
    capacity_per_bin: Option<usize>,
    fpr: Option<f64>,
    hasher: H,
    _phantom: PhantomData<T>,
}

impl<T, H> TreeBloomFilterBuilder<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    /// Create a new builder with default values.
    pub fn new() -> Self {
        Self {
            branching: None,
            capacity_per_bin: None,
            fpr: None,
            hasher: H::default(),
            _phantom: PhantomData,
        }
    }
    
    /// Set the branching factors for each level.
    pub fn branching(mut self, branching: Vec<usize>) -> Self {
        self.branching = Some(branching);
        self
    }
    
    /// Set the expected items per leaf bin.
    pub fn capacity_per_bin(mut self, capacity: usize) -> Self {
        self.capacity_per_bin = Some(capacity);
        self
    }
    
    /// Set the target false positive rate.
    pub fn false_positive_rate(mut self, fpr: f64) -> Self {
        self.fpr = Some(fpr);
        self
    }
    
    /// Set the custom hasher.
    pub fn hasher(mut self, hasher: H) -> Self {
        self.hasher = hasher;
        self
    }
    
    /// Build the TreeBloomFilter with configured parameters.
    pub fn build(self) -> Result<TreeBloomFilter<T, H>> {
        let branching = self.branching
            .ok_or_else(|| BloomCraftError::invalid_parameters("branching not set"))?;
        let capacity = self.capacity_per_bin
            .ok_or_else(|| BloomCraftError::invalid_parameters("capacity_per_bin not set"))?;
        let fpr = self.fpr
            .ok_or_else(|| BloomCraftError::invalid_parameters("fpr not set"))?;
        
        TreeBloomFilter::with_hasher(branching, capacity, fpr, self.hasher)
    }
}

impl<T, H> Default for TreeBloomFilterBuilder<T, H>
where
    T: Hash + Send + Sync,
    H: BloomHasher + Clone + Default,
{
    fn default() -> Self {
        Self::new()
    }
}

/// Configuration validator for TreeBloomFilter capacity planning.
///
/// # Examples
/// ```rust,no_run
/// # use bloomcraft::filters::tree::TreeConfig;
/// let config = TreeConfig {
///     branching: vec![5, 10],
///     capacity_per_bin: 5000,
///     target_fpr: 0.001,
/// };
///
/// match config.validate() {
///     Ok(stats) => println!("Estimated memory: {} MB", stats.memory_mb),
///     Err(e) => eprintln!("Invalid config: {}", e),
/// }
/// # Ok::<(), Box<dyn std::error::Error>>(())
/// ```
#[derive(Debug, Clone)]
pub struct TreeConfig {
    /// Branching factors for each level of the tree
    pub branching: Vec<usize>,
    /// Expected items per leaf bin
    pub capacity_per_bin: usize,
    /// Target false positive rate
    pub target_fpr: f64,
}

/// Statistics about a tree configuration.
#[derive(Debug, Clone)]
pub struct TreeCapacityStats {
    /// Total number of nodes (internal + leaf)
    pub total_nodes: usize,
    /// Number of leaf bins
    pub leaf_count: usize,
    /// Estimated memory usage in MB
    pub memory_mb: usize,
    /// Tree depth (number of levels)
    pub depth: usize,
}

impl TreeConfig {
    /// Validate configuration and return estimated statistics.
    ///
    /// # Errors
    /// Same validation as `TreeBloomFilter::with_hasher`
    pub fn validate(&self) -> Result<TreeCapacityStats> {
        use crate::core::params::optimal_m;
        
        // Validate depth
        if self.branching.is_empty() {
            return Err(BloomCraftError::invalid_parameters("Branching cannot be empty"));
        }
        
        if self.branching.len() > MAX_TREE_DEPTH {
            return Err(BloomCraftError::invalid_parameters(format!(
                "Depth {} exceeds maximum {}",
                self.branching.len(),
                MAX_TREE_DEPTH
            )));
        }
        
        // Calculate total nodes with overflow protection
        let leaf_count: usize = self.branching
            .iter()
            .try_fold(1usize, |acc, &b| acc.checked_mul(b))
            .ok_or_else(|| BloomCraftError::invalid_parameters(
                "Branching factors would overflow leaf count"
            ))?;
        
        let mut total_nodes: usize = 1;
        let mut partial_product: usize = 1;
        
        for &branching_factor in &self.branching {
            partial_product = partial_product.checked_mul(branching_factor)
                .ok_or_else(|| BloomCraftError::invalid_parameters(
                    "Branching factors would overflow node count"
                ))?;
            total_nodes = total_nodes.checked_add(partial_product)
                .ok_or_else(|| BloomCraftError::invalid_parameters(
                "Total node count would overflow"
            ))?;
        }
        
        // Check against limits
        if total_nodes > MAX_TOTAL_NODES {
            return Err(BloomCraftError::invalid_parameters(format!(
                "Total nodes {} exceeds maximum {}",
                total_nodes,
                MAX_TOTAL_NODES
            )));
        }
        
        // Estimate memory
        let bits_per_filter = optimal_m(self.capacity_per_bin, self.target_fpr);
        let bytes_per_filter = (bits_per_filter + 7) / 8;
        let node_overhead = std::mem::size_of::<TreeNode<String, StdHasher>>();
        let bytes_per_node = bytes_per_filter + node_overhead;
        
        let total_memory = total_nodes.checked_mul(bytes_per_node)
            .ok_or_else(|| BloomCraftError::invalid_parameters(
                "Memory calculation overflow"
            ))?;
        
        Ok(TreeCapacityStats {
            total_nodes,
            leaf_count,
            memory_mb: total_memory / (1024 * 1024),
            depth: self.branching.len(),
        })
    }
    
    /// Generate a human-readable capacity report.
    pub fn report(&self) -> String {
        match self.validate() {
            Ok(stats) => {
                format!(
                    "TreeBloomFilter Capacity Report\n\
                     ================================\n\
                     Configuration:\n\
                     - Branching: {:?}\n\
                     - Depth: {}\n\
                     - Capacity per bin: {}\n\
                     - Target FPR: {:.4}\n\
                     \n\
                     Estimated Usage:\n\
                     - Total nodes: {}\n\
                     - Leaf bins: {}\n\
                     - Memory: {} MB\n\
                     \n\
                     Status: VIABLE",
                    self.branching,
                    stats.depth,
                    self.capacity_per_bin,
                    self.target_fpr,
                    stats.total_nodes,
                    stats.leaf_count,
                    stats.memory_mb
                )
            }
            Err(e) => {
                format!(
                    "TreeBloomFilter Capacity Report\n\
                     ================================\n\
                     Configuration:\n\
                     - Branching: {:?}\n\
                     - Capacity per bin: {}\n\
                     - Target FPR: {:.4}\n\
                     \n\
                     Status: INVALID\n\
                     Error: {}",
                    self.branching,
                    self.capacity_per_bin,
                    self.target_fpr,
                    e
                )
            }
        }
    }
}


#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_new() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        assert_eq!(filter.depth(), 2);
        assert_eq!(filter.leaf_count(), 6);
        assert_eq!(filter.len(), 0);
        assert!(filter.is_empty());
    }

    #[test]
    fn test_insert_and_query() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        filter.insert_to_bin(&"hello".to_string(), &[0, 1]).unwrap();
        assert!(filter.contains(&"hello".to_string()));
        assert!(!filter.contains(&"goodbye".to_string()));
        assert_eq!(filter.len(), 1);
    }

    #[test]
    fn test_insert_auto() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
        
        filter.insert_auto(&"test".to_string()).unwrap();
        assert!(filter.contains(&"test".to_string()));
        
        // Should be deterministic
        let loc1 = filter.locate(&"test".to_string());
        filter.insert_auto(&"test".to_string()).unwrap();
        let loc2 = filter.locate(&"test".to_string());
        assert_eq!(loc1, loc2);
    }

    #[test]
    fn test_union() {
        let mut filter1: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        let mut filter2: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        filter1.insert_to_bin(&"a".to_string(), &[0, 0]).unwrap();
        filter2.insert_to_bin(&"b".to_string(), &[1, 1]).unwrap();
        
        filter1.union(&filter2).unwrap();
        assert!(filter1.contains(&"a".to_string()));
        assert!(filter1.contains(&"b".to_string()));
    }

    #[test]
    fn test_intersect() {
        let mut filter1: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        let mut filter2: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        filter1.insert_to_bin(&"a".to_string(), &[0, 0]).unwrap();
        filter1.insert_to_bin(&"b".to_string(), &[0, 0]).unwrap();
        filter2.insert_to_bin(&"b".to_string(), &[0, 0]).unwrap();
        filter2.insert_to_bin(&"c".to_string(), &[1, 1]).unwrap();
        
        filter1.intersect(&filter2).unwrap();
        assert!(filter1.contains(&"b".to_string()));
    }

    #[test]
    fn test_subtree_operations() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        filter.insert_to_bin(&"item".to_string(), &[0, 1]).unwrap();
        
        let subtree = filter.subtree_at(&[0]).unwrap();
        assert!(subtree.filter.contains(&"item".to_string()));
        
        filter.clear_subtree(&[0]).unwrap();

        let cleared_subtree = filter.subtree_at(&[0]).unwrap();
        assert!(!cleared_subtree.filter.contains(&"item".to_string()));

        assert!(!filter.contains_in_bin(&"item".to_string(), &[0, 1]).unwrap());
    }

    #[test]
    fn test_locate_in_range() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![3, 3], 1000, 0.01).unwrap();
        
        filter.insert_to_bin(&"item".to_string(), &[1, 2]).unwrap();
        
        let locs = filter.locate_in_range(&"item".to_string(), &[1]);
        assert_eq!(locs.len(), 1);
        assert_eq!(locs[0], vec![1, 2]);
    }

    #[test]
    fn test_builder() {
        let filter: Result<TreeBloomFilter<String>> = TreeBloomFilterBuilder::new()
            .branching(vec![2, 3])
            .capacity_per_bin(1000)
            .false_positive_rate(0.01)
            .build();
        
        assert!(filter.is_ok());
        let f = filter.unwrap();
        assert_eq!(f.depth(), 2);
        assert_eq!(f.leaf_count(), 6);
    }

    #[test]
    fn test_needs_resize() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2], 100, 0.01).unwrap();
        
        assert!(!filter.needs_resize());
        
        // Fill to saturation
        for i in 0..150 {
            filter.insert_to_bin(&format!("item{}", i), &[0]).unwrap();
        }
        
        assert!(filter.needs_resize());
    }

    #[cfg(debug_assertions)]
    #[test]
    fn test_validate_structure() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        assert!(filter.validate_structure().is_ok());
    }

    #[cfg(feature = "metrics")]
    #[test]
    fn test_health_check() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        let health = filter.health_check();
        assert!(matches!(health.status, HealthStatus::Healthy));
    }

    #[cfg(feature = "metrics")]
    #[test]
    fn test_prometheus_export() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2], 1000, 0.01).unwrap();
        
        let output = filter.export_prometheus();
        assert!(output.contains("tree_bloom_filter_items"));
        assert!(output.contains("tree_bloom_filter_load_factor"));
    }
   
    #[cfg(test)]
    #[cfg(feature = "proptest")]
    mod proptests {
        use super::*;
        use proptest::prelude::*;
        
        proptest! {
            #[test]
            fn no_false_negatives(items: Vec<String>) {
                let branching = vec![3, 4];
                let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(branching, 1000, 0.01).unwrap();
                
                for item in &items {
                    filter.insert_auto(item).unwrap();
                }
                
                // No false negatives
                for item in &items {
                    prop_assert!(filter.contains(item));
                }
            }
            
            #[test]
            fn insert_auto_deterministic(items: Vec<String>) {
                let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![4, 4], 1000, 0.01).unwrap();
                
                for item in &items {
                    filter.insert_auto(item).unwrap();
                }
                
                // Each item should always be in exactly one bin
                for item in &items {
                    let locations = filter.locate(item);
                    prop_assert_eq!(locations.len(), 1, 
                        "Item {:?} in {} bins (expected 1)", item, locations.len());
                }
            }
        }
    }

    #[test]
    fn test_depth_limit_enforced() {
        let too_deep = vec![2; MAX_TREE_DEPTH + 1];
        let result = TreeBloomFilter::<String>::new(too_deep, 1000, 0.01);
        assert!(result.is_err());
        
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("exceeds maximum"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_max_depth_allowed() {
        let max_depth = vec![2; MAX_TREE_DEPTH];
        let result = TreeBloomFilter::<String>::new(max_depth, 1000, 0.01);
        // Will likely fail due to node count overflow, but depth check should pass
        if let Ok(filter) = result {
            assert_eq!(filter.depth(), MAX_TREE_DEPTH);
        }
    }

    #[test]
    fn test_node_count_overflow_protection() {
        // This configuration overflows leaf count
        let huge_branching = vec![usize::MAX / 2, 10];
        let result = TreeBloomFilter::<String>::new(huge_branching, 1000, 0.01);
        assert!(result.is_err());
    }

    #[test]
    fn test_tree_config_validation() {
        let config = TreeConfig {
            branching: vec![5, 10, 20],
            capacity_per_bin: 1000,
            target_fpr: 0.01,
        };
        
        let stats = config.validate().unwrap();
        assert_eq!(stats.total_nodes, 1_056);
        assert_eq!(stats.leaf_count, 1_000);
        assert!(stats.memory_mb > 0);
    }

    #[test]
    fn test_tree_config_too_deep() {
        let config = TreeConfig {
            branching: vec![2; MAX_TREE_DEPTH + 1],
            capacity_per_bin: 100,
            target_fpr: 0.01,
        };
        
        assert!(config.validate().is_err());
    }

    #[test]
    fn test_insert_batch_overflow_protection() {
        let mut filter = TreeBloomFilter::<String>::new(vec![2], 100, 0.01).unwrap();
        filter.total_items = usize::MAX - 5;
        
        let item = "a".to_string();
        let items = vec![&item; 10];
        let result = filter.insert_batch_to_bin(&items, &[0]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::CapacityExceeded { .. } => {},
            _ => panic!("Expected CapacityExceeded error"),
        }
    }

    #[test]
    fn test_clear_deep_tree() {
        let _filter = TreeBloomFilter::<u32>::new(vec![2; 10], 100, 0.01).unwrap();
        // Clearing should not stack overflow
        // (Test passes if no panic)
    }

    #[test]
    fn test_locate_with_zero_allocation() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
        
        // Insert into multiple bins
        filter.insert_to_bin(&"test".to_string(), &[0, 0]).unwrap();
        filter.insert_to_bin(&"test".to_string(), &[1, 2]).unwrap();
        filter.insert_to_bin(&"test".to_string(), &[2, 3]).unwrap();
        
        // Collect using callback
        let mut paths = Vec::new();
        filter.locate_with(&"test".to_string(), |path| {
            paths.push(path.to_vec());
        });
        
        assert_eq!(paths.len(), 3);
        assert!(paths.contains(&vec![0, 0]));
        assert!(paths.contains(&vec![1, 2]));
        assert!(paths.contains(&vec![2, 3]));
    }

    #[test]
    fn test_locate_with_early_processing() {
        let mut filter: TreeBloomFilter<u32> = 
            TreeBloomFilter::new(vec![5, 10], 1000, 0.01).unwrap();
        
        // Insert into many bins
        for i in 0..5 {
            for j in 0..10 {
                filter.insert_to_bin(&42, &[i, j]).unwrap();
            }
        }
        
        // Process immediately without storing
        let mut count = 0;
        filter.locate_with(&42, |_path| {
            count += 1;
        });
        
        assert_eq!(count, 50);
    }

    #[test]
    fn test_locate_with_vs_locate_equivalence() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![4, 5], 1000, 0.01).unwrap();
        
        filter.insert_to_bin(&"item".to_string(), &[1, 2]).unwrap();
        filter.insert_to_bin(&"item".to_string(), &[3, 4]).unwrap();
        
        // Compare results
        let locate_result = filter.locate(&"item".to_string());
        
        let mut locate_with_result = Vec::new();
        filter.locate_with(&"item".to_string(), |path| {
            locate_with_result.push(path.to_vec());
        });
        
        assert_eq!(locate_result.len(), locate_with_result.len());
        for path in &locate_result {
            assert!(locate_with_result.contains(path));
        }
    }

    #[test]
    fn test_locate_iter_basic() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        filter.insert_to_bin(&"test".to_string(), &[0, 1]).unwrap();
        filter.insert_to_bin(&"test".to_string(), &[1, 2]).unwrap();
        
        let paths: Vec<_> = filter.locate_iter(&"test".to_string()).collect();
        
        assert_eq!(paths.len(), 2);
        assert!(paths.contains(&vec![0, 1]));
        assert!(paths.contains(&vec![1, 2]));
    }

    #[test]
    fn test_locate_iter_early_exit() {
        let mut filter: TreeBloomFilter<u32> = 
            TreeBloomFilter::new(vec![5, 10], 1000, 0.01).unwrap();
        
        // Insert into all bins
        for i in 0..5 {
            for j in 0..10 {
                filter.insert_to_bin(&999, &[i, j]).unwrap();
            }
        }
        
        // Take only first 3 matches
        let first_three: Vec<_> = filter.locate_iter(&999).take(3).collect();
        
        assert_eq!(first_three.len(), 3);
    }

    #[test]
    fn test_locate_iter_count() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
        
        for i in 0..3 {
            for j in 0..4 {
                filter.insert_to_bin(&"item".to_string(), &[i, j]).unwrap();
            }
        }
        
        // Count without allocating paths
        let count = filter.locate_iter(&"item".to_string()).count();
        
        assert_eq!(count, 12);
    }

    #[test]
    fn test_locate_iter_empty() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        let item = "nonexistent".to_string();
        let mut iter = filter.locate_iter(&item);
        
        assert!(iter.next().is_none());
    }

    #[test]
    fn test_locate_apis_consistency() {
        let mut filter: TreeBloomFilter<u64> = 
            TreeBloomFilter::new(vec![4, 5, 3], 1000, 0.01).unwrap();
        
        // Insert into sparse bins
        filter.insert_to_bin(&12345, &[0, 1, 2]).unwrap();
        filter.insert_to_bin(&12345, &[2, 3, 1]).unwrap();
        filter.insert_to_bin(&12345, &[3, 4, 0]).unwrap();
        
        // Collect via all three APIs
        let locate_result = filter.locate(&12345);
        
        let mut locate_with_result = Vec::new();
        filter.locate_with(&12345, |path| {
            locate_with_result.push(path.to_vec());
        });
        
        let locate_iter_result: Vec<_> = filter.locate_iter(&12345).collect();
        
        // All should return same paths
        assert_eq!(locate_result.len(), 3);
        assert_eq!(locate_with_result.len(), 3);
        assert_eq!(locate_iter_result.len(), 3);
        
        for path in &locate_result {
            assert!(locate_with_result.contains(path));
            assert!(locate_iter_result.contains(path));
        }
    }

    #[test]
    fn test_subtree_at_root() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        let root = filter.subtree_at(&[]).unwrap();
        assert_eq!(root.children.len(), 2);
    }

    #[test]
    fn test_subtree_at_valid_paths() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![3, 4, 2], 1000, 0.01).unwrap();
        
        // Valid partial path
        let node = filter.subtree_at(&[1]).unwrap();
        assert_eq!(node.children.len(), 4);
        
        // Valid full path to internal node
        let node = filter.subtree_at(&[2, 3]).unwrap();
        assert_eq!(node.children.len(), 2);
        
        // Valid path to leaf
        let leaf = filter.subtree_at(&[0, 1, 0]).unwrap();
        assert!(leaf.is_leaf());
    }

    #[test]
    fn test_subtree_at_path_too_long() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        // Path longer than depth (depth = 2)
        let result = filter.subtree_at(&[0, 1, 2]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("Path length 3 exceeds tree depth 2"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_subtree_at_index_out_of_bounds() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        // First level has branching factor 2, so index 2 is invalid
        let result = filter.subtree_at(&[2]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("Invalid index 2 at level 0"));
                assert!(message.contains("branching factor is 2"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_subtree_at_index_out_of_bounds_deep() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![3, 4, 2], 1000, 0.01).unwrap();
        
        // Second level has branching factor 4, so index 5 is invalid
        let result = filter.subtree_at(&[1, 5]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("Invalid index 5 at level 1"));
                assert!(message.contains("branching factor is 4"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_subtree_at_boundary_cases() {
        let filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
        
        // Max valid index at each level
        assert!(filter.subtree_at(&[2]).is_ok());
        assert!(filter.subtree_at(&[0, 3]).is_ok());
        
        // Just beyond max
        assert!(filter.subtree_at(&[3]).is_err());
        assert!(filter.subtree_at(&[0, 4]).is_err());
    }

    #[test]
    fn test_clear_subtree_path_too_long() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        let result = filter.clear_subtree(&[0, 1, 2]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("Path length 3 exceeds tree depth 2"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_clear_subtree_index_out_of_bounds() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
        
        let result = filter.clear_subtree(&[1, 5]);
        
        assert!(result.is_err());
        match result.unwrap_err() {
            BloomCraftError::InvalidParameters { message } => {
                assert!(message.contains("Invalid index 5 at level 1"));
                assert!(message.contains("branching factor is 4"));
            }
            _ => panic!("Expected InvalidParameters error"),
        }
    }

    #[test]
    fn test_clear_subtree_valid() {
        let mut filter: TreeBloomFilter<String> = 
            TreeBloomFilter::new(vec![2, 3], 1000, 0.01).unwrap();
        
        // Insert data into specific subtree
        filter.insert_to_bin(&"item1".to_string(), &[0, 0]).unwrap();
        filter.insert_to_bin(&"item2".to_string(), &[0, 1]).unwrap();
        
        // Clear that subtree
        filter.clear_subtree(&[0]).unwrap();
        
        // Verify subtree is cleared
        let subtree = filter.subtree_at(&[0]).unwrap();
        assert_eq!(subtree.item_count, 0);
        
        for child in subtree.children.iter() {
            assert_eq!(child.item_count, 0);
        }
    }

    #[test]
    fn test_clear_subtree_root() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![2, 2], 1000, 0.01).unwrap();
        
        filter.insert_to_bin(&"item".to_string(), &[0, 0]).unwrap();
        filter.insert_to_bin(&"item".to_string(), &[1, 1]).unwrap();
        
        // Clear entire tree
        filter.clear_subtree(&[]).unwrap();
        
        assert_eq!(filter.root.item_count, 0);
        assert_eq!(filter.total_items, 2);
    }

    #[test]
    fn test_subtree_at_and_clear_consistency() {
        let mut filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![3, 4, 2], 1000, 0.01).unwrap();
        
        // Test that invalid paths fail the same way in both methods
        let invalid_paths = vec![
            vec![10],           
            vec![0, 20],        
            vec![1, 2, 5],      
            vec![0, 0, 0, 0],   
        ];
        
        for path in &invalid_paths {
            // Test subtree_at
            let subtree_result = filter.subtree_at(path);
            assert!(subtree_result.is_err(), "subtree_at should fail for {:?}", path);
            let subtree_msg = format!("{}", subtree_result.unwrap_err());  // ✅ Consume it immediately
    
            // Test clear_subtree (now filter is not borrowed)
            let clear_result = filter.clear_subtree(path);
            assert!(clear_result.is_err(), "clear_subtree should fail for {:?}", path);
            let clear_msg = format!("{}", clear_result.unwrap_err());
    
            // Compare
            assert_eq!(subtree_msg, clear_msg, "Error messages should match for {:?}", path);
        }
    }

    #[test]
    fn test_error_message_quality() {
        let filter: TreeBloomFilter<String> = TreeBloomFilter::new(vec![5, 10, 3], 1000, 0.01).unwrap();
        
        // Path too long
        let result = filter.subtree_at(&[0, 0, 0, 0]);
        let err = result.unwrap_err().to_string();
        assert!(err.contains("Path length 4"));
        assert!(err.contains("tree depth 3"));
        
        // Index out of bounds with context
        let result = filter.subtree_at(&[0, 15]);
        let err = result.unwrap_err().to_string();
        assert!(err.contains("Invalid index 15"));
        assert!(err.contains("level 1"));
        assert!(err.contains("branching factor is 10"));
        assert!(err.contains("valid range: 0..10"));
    }

    #[cfg(all(test, feature = "serde"))]
    mod serde_security_tests {
        use super::*;
        use crate::hash::StdHasher;
        
        #[test]
        fn test_serialize_includes_type_id() {
            let filter: TreeBloomFilter<String, StdHasher> = TreeBloomFilter::new(vec![2, 2], 100, 0.01).unwrap();
            
            let serialized = serde_json::to_string(&filter).unwrap();
            
            // Should contain both fields
            assert!(serialized.contains("hasher_type"));
            assert!(serialized.contains("hasher_type_id"));
            
            // TypeId should be in format "TypeId { t: ... }"
            assert!(serialized.contains("TypeId"));
        }
        
        #[test]
        fn test_deserialize_with_matching_type_id() {
            let original: TreeBloomFilter<String, StdHasher> = TreeBloomFilter::new(vec![2, 2], 100, 0.01).unwrap();
            
            let serialized = serde_json::to_string(&original).unwrap();
            
            // Should deserialize successfully
            let deserialized: TreeBloomFilter<String, StdHasher> = 
                serde_json::from_str(&serialized).unwrap();
            
            assert_eq!(deserialized.depth(), original.depth());
        }
        
        #[test]
        fn test_deserialize_rejects_wrong_type_id() {
            // Create a filter with StdHasher
            let filter: TreeBloomFilter<String, StdHasher> = TreeBloomFilter::new(vec![2], 100, 0.01).unwrap();
            
            let mut serialized = serde_json::to_value(&filter).unwrap();
            
            // Tamper with the type_id field
            if let Some(obj) = serialized.as_object_mut() {
                obj.insert(
                    "hasher_type_id".to_string(), 
                    serde_json::Value::String("TypeId { t: 12345678901234567890 }".to_string())
                );
            }
            
            let tampered = serde_json::to_string(&serialized).unwrap();
            
            // Should fail to deserialize
            let result: Result<TreeBloomFilter<String, StdHasher>, _> = serde_json::from_str(&tampered);
            
            assert!(result.is_err());
            let err = result.unwrap_err().to_string();
            assert!(err.contains("TypeId mismatch"));
        }
        
        #[test]
        fn test_deserialize_backward_compatibility() {
            // Simulate old format without hasher_type_id
            let old_format = r#"{
                "root": {
                    "filter": {"bits": [], "num_hash": 3, "hasher": null},
                    "item_count": 0,
                    "children": [],
                    "metadata": {"path": [], "level": 0}
                },
                "branching": [2, 2],
                "capacity_per_bin": 100,
                "target_fpr": 0.01,
                "total_items": 0,
                "hasher_type": "bloomcraft::hash::StdHasher"
            }"#;
            
            // Should still deserialize (falls back to string check)
            let result: Result<TreeBloomFilter<String, StdHasher>, _> = serde_json::from_str(old_format);
            
            // May fail due to simplified test data structure, but shouldn't panic
            // In real code with proper structure, this would succeed with a warning
            if let Err(e) = result {
                // Error should be about structure, not missing hasher_type_id
                assert!(!e.to_string().contains("Missing hasher type validation fields"));
            }
        }
        
        #[test]
        fn test_deserialize_rejects_missing_both_fields() {
            // Create JSON without either validation field
            let malicious = r#"{
                "root": {
                    "filter": {"bits": [], "num_hash": 3, "hasher": null},
                    "item_count": 0,
                    "children": [],
                    "metadata": {"path": [], "level": 0}
                },
                "branching": [2],
                "capacity_per_bin": 100,
                "target_fpr": 0.01,
                "total_items": 0
            }"#;
            
            let result: Result<TreeBloomFilter<String, StdHasher>, _> = 
                serde_json::from_str(malicious);
            
            assert!(result.is_err());
            // Should fail during validation or due to missing required fields
        }
        
        #[test]
        fn test_type_id_is_stable_within_process() {
            // TypeId should be consistent within the same binary
            let id1 = std::any::TypeId::of::<StdHasher>();
            let id2 = std::any::TypeId::of::<StdHasher>();
            
            assert_eq!(id1, id2);
            
            // Debug representation should also be consistent
            let debug1 = format!("{:?}", id1);
            let debug2 = format!("{:?}", id2);
            
            assert_eq!(debug1, debug2);
        }
        
        #[test]
        fn test_type_id_differs_for_different_types() {
            use crate::hash::WyHasher;
            
            let std_id = std::any::TypeId::of::<StdHasher>();
            let wy_id = std::any::TypeId::of::<WyHasher>();
            
            assert_ne!(std_id, wy_id);
            
            let std_debug = format!("{:?}", std_id);
            let wy_debug = format!("{:?}", wy_id);
            
            assert_ne!(std_debug, wy_debug);
        }
        
        #[test]
        fn test_round_trip_preserves_type_safety() {
            let original: TreeBloomFilter<u64, StdHasher> = 
                TreeBloomFilter::new(vec![3, 4], 1000, 0.01).unwrap();
            
            // Serialize
            let serialized = serde_json::to_string(&original).unwrap();
            
            // Deserialize with correct type
            let correct: TreeBloomFilter<u64, StdHasher> = 
                serde_json::from_str(&serialized).unwrap();
            
            assert_eq!(correct.depth(), 2);
            assert_eq!(correct.leaf_count(), 12);
        }
    }
}
